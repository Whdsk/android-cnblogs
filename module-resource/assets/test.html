<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>博文</title>
    <link rel="stylesheet" type="text/css" href="css/blog-common.css">
    <link type="text/css" rel="stylesheet" href="css/shCore.css"/>
    <!--<link type="text/css" rel="stylesheet" href="css/shCoreDefault.css"  id="CodeStyle"/>-->
    <link type="text/css" rel="stylesheet" href="css/shThemeRDark.css"/>
    <link rel="stylesheet" type="text/css" href="css/bootstrap.min.css">
    <link rel="stylesheet" type="text/css" href="css/bootstrap-theme.min.css">
    <link rel="stylesheet" type="text/css" href="css/rae.css" id="RaeStyle">
    <link rel="stylesheet" type="text/css"
          href="http://www.raeblog.com/cnblogs/Content/app/rae-ext.css"/>
    <link rel="stylesheet" type="text/css" href="css/rae-night.css"/>

    <script src="js/jquery.js" type="text/javascript"></script>
    <script src="js/highlight.min.js" type="text/javascript"></script>
    <script type="text/javascript" src="js/highlighter/shCore.js"></script>
    <script type="text/javascript" src="js/highlighter/shAutoloader.js"></script>
    <script src="js/clipboard.min.js" type="text/javascript"></script>
    <script src="js/encode.js" type="text/javascript"></script>
    <script src="js/blog-common.js" type="text/javascript"></script>
    <script src="js/bootstrap.min.js" type="text/javascript"></script>
    <script src="js/rae.js" type="text/javascript"></script>
    <script src="http://www.raeblog.com/cnblogs/Content/app/rae-ext.js"
            type="text/javascript"></script>
    <script type="text/javascript">
    	var width = 0;

    	// 加载主题
    	function loadTheme(isNightMode){
    		if(typeof(app) !="object"){
    			return;
    		}

    		if(typeof(isNightMode) == "undefined"){
		    	isNightMode = app.isNightMode(); // 是否为夜间模式
		    }
		    if(isNightMode){
		    	$("#RaeStyle").attr("href","css/rae-night.css");
		    }else{
		    	$("#RaeStyle").attr("href","css/rae.css");
		    }
		}
		// 先加载主题
		loadTheme();

		function path() {
			var args = arguments,
			result = [];
			for (var i = 0; i < args.length; i++)
				result.push(args[i].replace('$', 'js/highlighter/'));
			return result
		}

		$(document).ready(function(){
			width = $("body").width();
			load();
			SyntaxHighlighter.autoloader.apply(null, path(
				'applescript            $shBrushAppleScript.js',
				'actionscript3 as3      $shBrushAS3.js',
				'bash shell properties  $shBrushBash.js',
				'coldfusion cf          $shBrushColdFusion.js',
				'cpp c                  $shBrushCpp.js',
				'c# c-sharp csharp      $shBrushCSharp.js',
				'css                    $shBrushCss.js',
				'delphi pascal          $shBrushDelphi.js',
				'diff patch pas         $shBrushDiff.js',
				'erl erlang             $shBrushErlang.js',
				'groovy                 $shBrushGroovy.js',
				'java                   $shBrushJava.js',
				'jfx javafx             $shBrushJavaFX.js',
				'js jscript javascript  $shBrushJScript.js',
				'perl pl                $shBrushPerl.js',
				'php                    $shBrushPhp.js',
				'text plain             $shBrushPlain.js',
				'py python              $shBrushPython.js',
				'ruby rails ror rb      $shBrushRuby.js',
				'sass scss              $shBrushSass.js',
				'scala                  $shBrushScala.js',
				'sql                    $shBrushSql.js',
				'vb vbnet               $shBrushVb.js',
				'xml xhtml xslt html    $shBrushXml.js'
				));
			try{
				SyntaxHighlighter.all();
				markdown_highlight();
			}catch(e){
			}

	});

		// 加载图片
		function loadImage(){
			$("img").each(function(key,val){
				var src = $(val).attr("src");

				getImageWidth(src,function(w,h){
					var screenWidth = $(document).width();
			    	// 图片适配屏幕
			    	if(screenWidth>0 && w< screenWidth/2){
			    		$(val).css("width","auto");
			    	}
			    })

				$(val).load(function(){
					$(this).addClass("img-thumbnail");
				});
			});
		}

		function load(){

			loadTheme();
			if(typeof(app) =="object"){
				var blog = app.getBlog();
				if(blog!=""){
					blog = $.parseJSON(blog);
					$("#blog_content").html("");
					$("#blog_title").html(blog.title);
					$("#blog_date").text(blog.postDate);
					if(blog.content==null|| blog.content==""){
						$("#blog_content").append("<p>接口缺失正文内容，可能由于博客发布时间已经久远，接口任性就是没有返回数据。</p><p>你可以尝试点击下面阅读原文阅读，也可以点击右上方的更多按钮查看原文。</p><p><a href='"+blog.url +"' class='a-source'>【阅读原文】</a></p>");
					}else{
						$("#blog_content").append(blog.content);
					}
				}
			}

			try{
                //  官网，调用的方法，适配代码折叠
                fixPostBody();
                loadImage();
                initImage();
                // 重新设置代码高亮
                refreshCodeTheme();
            }catch(e){
            	console.error(e);
            }
        }


    </script>
</head>
<body>
<div class="container-fluid">
    <div id="header">
        <h3 id="blog_title"></h3>
        <span id="blog_date"></span>
        <!--<a href="javascript:window.locatrefreshCategoryload()">刷新页面</a>-->
    </div>
    <div id="blog_content">
        <h1>1.概述</h1>
        <p>　　Kafka Streams 是一个用来处理流式数据的库，属于Java类库，它并不是一个流处理框架，和Storm，Spark
            Streaming这类流处理框架是明显不一样的。那这样一个库是做什么的，能应用到哪些场合，如何使用。笔者今天就给大家来一一剖析这些内容。</p>
        <h1>2.内容</h1>
        <p>　　首先，我们研究这样一个库，需要知道它是做什么的。Kafka
            Streams是一个用来构建流处理应用的库，和Java的那些内置库一样，以一种分布式的容错方式来处理一些事情。当前，业界用于流处理的计算框架包含有：Flink，Spark，Storm等等。Kafka
            Streams处理完后的结果可以回写到Topic中，也可以外接其他系统进行落地。包含以下特性：</p>
        <ul>
            <li>事件区分：记录数据发生的时刻</li>
            <li>时间处理：记录数据被流处理应用开始处理的时刻，如记录被消费的时刻</li>
            <li>开窗</li>
            <li>状态管理：本身应用不需要管理状态，如若需要处理复杂的流处理应用（分组，聚合，连接等）</li>
        </ul>
        <p>　　Kafka Streams使用是很简单的，这一点通过阅读官方的示例代码就能发现，另外它利用Kafka的并发模型来完成负载均衡。</p>
        <h2>2.1 优势</h2>
        <p>　　在Kafka集群上，能够很便捷的使用，亮点如下图所示：</p>
        <p>
            <img src="http://images2017.cnblogs.com/blog/666745/201709/666745-20170914100036657-1859623565.png"
                 alt=""/></p>
        <ul>
            <li>能够设计一些轻量级的Client类库，和现有的Java程序整合</li>
            <li>不需要额外的Kafka集群，利用现有的Kafka集群的分区实现水平扩展</li>
            <li>容错率，高可用性</li>
            <li>多平台部署，支持Mac，Linux和Windows系统</li>
            <li>权限安全控制</li>
        </ul>
        <h2>2.2 Sample</h2>
        <p>　　Kafka
            Streams是直接构建与Kafka的基础之上的，没有了额外的流处理集群，Table和一些有状态的处理完全整合到了流处理本身。其核心代码非常的简介。简而言之，就和你写Consumer或Producer一样，但是Kafka
            Streams更加的简洁。</p>
        <h2>2.3 属性</h2>
        <table border="0">
            <tbody>
            <tr>
                <td>名称</td>
                <td>描述</td>
                <td>类型</td>
                <td>默认值</td>
                <td>级别</td>
            </tr>
            <tr>
                <td>application.id</td>
                <td>流处理标识，对应一个应用需要保持一致，用作消费的group.id</td>
                <td>string</td>
                <td>&nbsp;</td>
                <td>高</td>
            </tr>
            <tr>
                <td>bootstrap.servers</td>
                <td>用来发现Kafka的集群节点，不需要配置所有的Broker</td>
                <td>list</td>
                <td>&nbsp;</td>
                <td>高</td>
            </tr>
            <tr>
                <td>replication.factor</td>
                <td>复制因子</td>
                <td>int</td>
                <td>1</td>
                <td>高</td>
            </tr>
            <tr>
                <td>state.dir</td>
                <td>本地状态存储目录</td>
                <td>string</td>
                <td>/tmp/kafka-streams</td>
                <td>高</td>
            </tr>
            <tr>
                <td>cache.max.bytes.buffering</td>
                <td>所有线程的最大缓冲内存</td>
                <td>long</td>
                <td>10485760</td>
                <td>中</td>
            </tr>
            <tr>
                <td>client.id</td>
                <td>客户端逻辑名称，用于标识请求位置</td>
                <td>string</td>
                <td>""</td>
                <td>中</td>
            </tr>
            <tr>
                <td>default.key.serde</td>
                <td>对Key序列化或反序列化类，实现于Serde接口</td>
                <td>class</td>
                <td>org.apache.kafka.common.serialization.Serdes$ByteArraySerde</td>
                <td>中</td>
            </tr>
            <tr>
                <td>default.value.serde</td>
                <td>对Value序列化或反序列化类，实现与Serde接口</td>
                <td>class</td>
                <td>org.apache.kafka.common.serialization.Serdes$ByteArraySerde</td>
                <td>中</td>
            </tr>
            <tr>
                <td>...</td>
                <td>...</td>
                <td>...</td>
                <td>...</td>
                <td>...</td>
            </tr>
            </tbody>
        </table>
        <p>　　这里只是列举了部分Kafka Streams的属性值，更多的详情可参考<a
                href="https://kafka.apache.org/documentation/#streamsconfigs" target="_blank">Kafka
            Streams Configs</a>。</p>
        <h1>3.示例</h1>
        <p>　　下面，我们可以通过一个示例代码，来熟悉Kafka Streams的运行流程，如下所示：</p>
        <div class="cnblogs_Highlighter">
 <pre class="brush:java;gutter:true;">import org.apache.kafka.common.serialization.Serdes;
 import org.apache.kafka.streams.KafkaStreams;
 import org.apache.kafka.streams.StreamsConfig;
 import org.apache.kafka.streams.kstream.KStream;
 import org.apache.kafka.streams.kstream.KStreamBuilder;
 import org.apache.kafka.streams.kstream.KTable;

 import java.util.Arrays;
 import java.util.Properties;

 public class WordCountApplication {

 public static void main(final String[] args) throws Exception {
 Properties config = new Properties();
 config.put(StreamsConfig.APPLICATION_ID_CONFIG, "wordcount_topic_appid");
 config.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "kafka1:9092,kafka2:9092,kafka3:9092");
 config.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass());
 config.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());

 KStreamBuilder builder = new KStreamBuilder();
 KStream&lt;String, String&gt; textLines = builder.stream("TextLinesTopic");
 KTable&lt;String, Long&gt; wordCounts = textLines
 .flatMapValues(textLine -&gt; Arrays.asList(textLine.toLowerCase().split("\\W+")))
 .groupBy((key, word) -&gt; word)
 .count("Counts");
 wordCounts.to(Serdes.String(), Serdes.Long(), "WordsWithCountsTopic");

 KafkaStreams streams = new KafkaStreams(builder, config);
 streams.start();
 }

 }
 </pre>
        </div>
        <p>　　从代码中，我们可以看出Kafka Streams为上层流定义了两种基本抽象：</p>
        <ul>
            <li>KStream：可以从一个或者多个Topic源来创建</li>
            <li>KTable：从一个Topic源来创建</li>
        </ul>
        <p>
            　　这两者的区别是，前者比较像传统意义上的流，可以把每一个K/V看成独立的，后者的思想更加接近与Map的概念。同一个Key输入多次，后者是会覆盖前者的。而且，KStream和KTable都提供了一系列的转换操作，每个操作可以产生一个或者多个KStream和KTable对象，所有这些转换的方法连接在一起，就形成了一个复杂的Topology。由于KStream和KTable是强类型，这些转换都被定义为通用函数，这样在使用的时候让用户指定输入和输出数据类型。</p>
        <p>
            　　另外，无状态的转换不依赖于处理的状态，因此不需要状态仓库。有状态的转换则需要进行存储相应的状态用于处理和生成结果。例如，在进行聚合操作的时候，一个窗口状态用于保存当前预定义收到的值，然后转换获取累计的值，再做计算。</p>
        <p>　　在处理完后，对于结果集用户可以持续的将结果回写到Topic，也可以通过KStream.to() 或者 KTable.to() 方法来实现。</p>
        <h1>4.总结</h1>
        <p>　　通过对Kafka Streams的研究，它的优势可以总结为以下几点。首先，它提供了轻量级并且易用的API来有效的降低流数据的开发成本，之前要实现这类处理，需要使用Spark
            Streaming，Storm，Flink，或者自己编写Consumer。其次，它开发的应用程序可以支持在YARN，Mesos这类资源调度中，使用方式灵活。而对于异步操作，不是很友好，需要谨慎处理；另外，对SQL语法的支持有限，需要额外开发。</p>
        <h1>5.结束语</h1>
        <p>　　这篇博客就和大家分享到这里，如果大家在研究学习的过程当中有什么问题，可以加群进行讨论或发送邮件给我，我会尽我所能为您解答，与君共勉。</p>
    </div>


</div>
</body>
</html>